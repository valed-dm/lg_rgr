# Logistic Regression
Задание: реализовать свой логистический регрессор, который будет
классифицировать отзывы из Amazon. Большая часть работы уже проделана и
описана в homework.ipynb, в основном нужно дописать
dmia/classifiers/logistic_regression.py.

## Актуализация logistic_regression.py
Первым шагом получаем псевдослучайные выборки образцов данных заданного размера
использя результат np.random.choice в качестве маски:

```python
indices = np.random.choice(num_train, batch_size, replace=True)
x_batch = x[indices]
y_batch = y[indices]
```

Далее рассчитываются значения loss, gradient_w для оптимизированного обучения модели
с использованием метода градиентного спуска.
- loss: измеряет насколько предсказанные значения соответствуют актуальным.
- gradient_w: с учетом весов модели корректирует данные для максимального соответствия актуальным

### Метод loss:
scores: произведение двух массивов для получения комбинированного значения слово/вес.
```python
scores = x_batch.dot(self.w)
```
probs: статистическая функция для расчета предсказанных вероятностей.
```python
probs = 1 / (1 + np.exp(-scores))
```
dscores: определяет разность между предсказанными и актуальными значениями.
```python
dscores = probs - y_batch
```
loss: рассчитывает среднее логарифмическое отклонение по выборке.
```python
loss = -np.mean(y_batch * np.log(probs) + (1 - y_batch) * np.log(1 - probs))
```
gradient: рассчитывает градиент потерь с учетом фактора веса
```python
gradient = x_batch.T.dot(dscores) / num_train
```
значения loss, dw регуляризуются с учетом систематического отклонения
```python
loss += 0.5 * reg * np.sum(self.w[:-1] ** 2)
gradient[:-1] += reg * self.w[:-1]
```

### Реализация метода градиентного спуска:
```python
self.w -= learning_rate * grad_w
```
self.w: текущие веса модели

grad_w: градиент отклонения с учетом весов. Задает направление и величину корректировки
весов для уточнения расчетных значений модели.

learning_rate: задает величину шагов оптимизации весов модели. При уменьшении увеличивается
время обработки данных, в противном случае понижается достоверность модели.
Пример: w=0.5−0.01×0.1, w=0.5−0.001, w=0.499

Алгоритм работы заключается в многократном уточнении весов модели на разных выборках данных из
обучающего массива с постепенным приближением к заданной точности предсказания.

### Метод predict_proba
Подсчитывает вероятность принадлежности объекта к обоим классам (0 и 1) и возвращает массив
двойных значений для каждого объекта.

### Метод predict
Классифицирует принадлежность объекта на основе максимального из двух значений.

## Результат:
Сравнение с sklearn.linear_model.LogisticRegression показывает практически одинаковую точность
предсказания полученной модели на уровне чуть выше 80% совпадений.
